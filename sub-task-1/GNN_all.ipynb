{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = \"cuda\" \n",
    "\n",
    "num_features = 49\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "norm = nn.BatchNorm1d(num_features, affine=False)\n",
    "\n",
    "negative_sampler = dgl.dataloading.negative_sampler.Uniform(1)\n",
    "sampler = dgl.dataloading.NeighborSampler([1000, 1000])\n",
    "sampler = dgl.dataloading.as_edge_prediction_sampler(\n",
    "    sampler, negative_sampler=negative_sampler\n",
    ")\n",
    "\n",
    "def load_graph(url):\n",
    "    es = pickle.load(open('{}/es.pkl'.format(url), 'rb'))\n",
    "    ndata = pickle.load(open('{}/ndata.pkl'.format(url), 'rb'))\n",
    "\n",
    "    g = dgl.graph((es[0], es[1]))\n",
    "    g = dgl.add_reverse_edges(g)\n",
    "\n",
    "    g.ndata['feat'] = norm(torch.tensor(ndata, dtype=torch.float32))\n",
    "\n",
    "    eid = torch.concat((g.in_edges(0, 'eid'), g.out_edges(0, 'eid')))\n",
    "\n",
    "    return dgl.dataloading.DataLoader(\n",
    "        g, \n",
    "        eid, \n",
    "        sampler, \n",
    "        device=device, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,  \n",
    "        drop_last=False,  \n",
    "        num_workers=0,  \n",
    "    )\n",
    "\n",
    "# for file in os.listdir('graph/Ponzi'):\n",
    "#     dl = load_graph('graph/Ponzi/{}'.format(file))\n",
    "#     print(len(dl))\n",
    "\n",
    "# print(sum([len(l)for l in train_dataloaders]), sum([len(l)for l in test_dataloaders]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv, GATv2Conv, GATConv, GraphConv\n",
    "\n",
    "class SAGE_GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(SAGE_GCN, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='gcn')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, aggregator_type='gcn')\n",
    "        self.h_feats = h_feats\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[: mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[: mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        h = F.relu(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class SAGE_MEAN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(SAGE_MEAN, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, aggregator_type='mean')\n",
    "        self.h_feats = h_feats\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[: mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[: mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        h = F.relu(h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "class SAGE_POOL(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(SAGE_POOL, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='pool')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, aggregator_type='pool')\n",
    "        self.h_feats = h_feats\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[: mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[: mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        h = F.relu(h)\n",
    "        return h\n",
    "    \n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_feats, h_feats, num_heads=3)\n",
    "        self.conv2 = GATConv(h_feats, h_feats, num_heads=3)\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[: mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[: mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        h = h.mean(1)\n",
    "        h = F.relu(h)\n",
    "        return h\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, h_feats)\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        h_dst = x[: mfgs[0].num_dst_nodes()]\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[: mfgs[1].num_dst_nodes()]\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))\n",
    "        h = F.relu(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = h\n",
    "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
    "            return g.edata[\"score\"][:, 0]\n",
    "\n",
    "predictor = DotPredictor().to(device)\n",
    "\n",
    "def metrics(pos_score, neg_score):\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    l = F.mse_loss\n",
    "    for score in pos_score:\n",
    "        if l(score, torch.ones_like(score)) < l(score, torch.zeros_like(score)):\n",
    "            TP+=1\n",
    "        else:\n",
    "            FP+=1\n",
    "    for score in neg_score:\n",
    "        if l(score, torch.ones_like(score)) > l(score, torch.zeros_like(score)):\n",
    "            TN+=1\n",
    "        else:\n",
    "            FN+=1\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "def test(data_loader, model):\n",
    "    model.eval()\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for input_nodes, pos_graph, neg_graph, mfgs in data_loader:\n",
    "            inputs = mfgs[0].srcdata[\"feat\"]\n",
    "            outputs = model(mfgs, inputs)\n",
    "            pos_score = predictor(pos_graph, outputs)\n",
    "            neg_score = predictor(neg_graph, outputs)\n",
    "            tp, fp, tn, fn = metrics(pos_score, neg_score)\n",
    "            TP += tp\n",
    "            FP += fp\n",
    "            TN += tn\n",
    "            FN += fn\n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tqdm\n",
    "\n",
    "epoch = 50\n",
    "batch_size = 32\n",
    "\n",
    "for times in range(1, 5):\n",
    "    # ['Money Laundering', 'Gambles', 'Blackmail', 'Ponzi']\n",
    "    for t in ['Money Laundering', 'Gambles', 'Blackmail', 'Ponzi']:\n",
    "        #['GCN', 'GAT', 'SAGE_POOL', 'SAGE_MEAN', 'SAGE_GCN']\n",
    "        for t2 in ['GCN', 'GAT', 'SAGE_POOL', 'SAGE_MEAN', 'SAGE_GCN']:\n",
    "            files = os.listdir('graph/{}'.format(t))\n",
    "\n",
    "            train_dataloaders = []\n",
    "            test_dataloaders = []\n",
    "\n",
    "            if t == 'Money Laundering':\n",
    "                train_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f not in ['17UVSMegvrzfobKC82dHXpZLtLcqzW9stF', '3F2sZ4jbhvDKQdGbHYPC6ZxFXEau2m5Lqj']]\n",
    "                test_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f in ['17UVSMegvrzfobKC82dHXpZLtLcqzW9stF', '3F2sZ4jbhvDKQdGbHYPC6ZxFXEau2m5Lqj']]\n",
    "            elif t == 'Gambles':\n",
    "                train_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f not in ['1DzF87L4vQqtvK9VPzr8KShck141MZFXTi', '1PhioUeHy92gkLtUan7sWGH9EYXyjoKkha']]\n",
    "                test_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f in ['1DzF87L4vQqtvK9VPzr8KShck141MZFXTi', '1PhioUeHy92gkLtUan7sWGH9EYXyjoKkha']]\n",
    "            elif t == 'Blackmail':\n",
    "                train_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f not in ['1HMsu3Dg3ocegPN2psqQtnsgZESeHVuxmN', '1JaF87nh5MV47ZbqjamaxgZ7mtAYSDgFd9']]\n",
    "                test_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f in ['1HMsu3Dg3ocegPN2psqQtnsgZESeHVuxmN', '1JaF87nh5MV47ZbqjamaxgZ7mtAYSDgFd9']]\n",
    "            elif t == 'Ponzi':\n",
    "                train_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f not in ['1MHwLU6hqHi7HcZENp4XsZQkYb2nNWGBLf', '31murN3u4dvWjVLEdSQRnhnPeuorxAxcer']]\n",
    "                test_dataloaders = [load_graph('graph/{}/{}'.format(t, f)) for f in files if f in ['1MHwLU6hqHi7HcZENp4XsZQkYb2nNWGBLf', '31murN3u4dvWjVLEdSQRnhnPeuorxAxcer']]\n",
    "            \n",
    "            if t2 == 'GCN':\n",
    "                model = GCN(num_features, num_features*3).to(device)\n",
    "            elif t2 == 'GAT':\n",
    "                model = GAT(num_features, num_features*3).to(device)\n",
    "            elif t2 == 'SAGE_POOL':\n",
    "                model = SAGE_POOL(num_features, num_features*3).to(device)\n",
    "            elif t2 == 'SAGE_MEAN':\n",
    "                model = SAGE_MEAN(num_features, num_features*3).to(device)\n",
    "            elif t2 == 'SAGE_GCN':\n",
    "                model = SAGE_GCN(num_features, num_features*3).to(device)\n",
    "                \n",
    "            opt = torch.optim.Adam(list(model.parameters()) + list(predictor.parameters()), lr=0.001)\n",
    "            \n",
    "            tqdm_epoch = tqdm.tqdm([i for i in range(epoch)], desc='{}_{}'.format(t, t2))\n",
    "            result_file = open('result/sub-task-1/{}_{}_{}_{}.txt'.format(t, t2, batch_size, times), 'w+')\n",
    "            for e in tqdm_epoch:\n",
    "                loss_sum = 0\n",
    "                for train_dataloader in train_dataloaders:\n",
    "                    for input_nodes, pos_graph, neg_graph, mfgs in train_dataloader:\n",
    "                        inputs = mfgs[0].srcdata[\"feat\"]\n",
    "\n",
    "                        outputs = model(mfgs, inputs)\n",
    "                        pos_score = predictor(pos_graph, outputs)\n",
    "                        neg_score = predictor(neg_graph, outputs)\n",
    "                        \n",
    "                        score = torch.cat([pos_score, neg_score])\n",
    "                        label = torch.cat(\n",
    "                            [torch.ones_like(pos_score), torch.zeros_like(neg_score)]\n",
    "                        )\n",
    "                        loss = F.mse_loss(score, label)\n",
    "                        loss_sum+=loss.item()\n",
    "                        \n",
    "                        opt.zero_grad()\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "                        \n",
    "                model.eval()\n",
    "                TP, FP, TN, FN = 0,0,0,0\n",
    "                for test_dataloader in test_dataloaders:\n",
    "                    _TP, _FP, _TN, _FN = test(test_dataloader, model)\n",
    "                    TP+=_TP\n",
    "                    FP+=_FP\n",
    "                    TN+=_TN\n",
    "                    FN+=_FN\n",
    "                P = TP / (TP + FP) if (TP + FP) else 0\n",
    "                R = TP / (TP + FN) if (TP + FN) else 0\n",
    "                F1 = 2 * P * R / (P + R) if (P + R) else 0\n",
    "                \n",
    "                TP2, FP2, TN2, FN2 = 0,0,0,0\n",
    "                for train_dataloader in train_dataloaders:\n",
    "                    _TP2, _FP2, _TN2, _FN2 = test(train_dataloader, model)\n",
    "                    TP2+=_TP2\n",
    "                    FP2+=_FP2\n",
    "                    TN2+=_TN2\n",
    "                    FN2+=_FN2\n",
    "                P2 = TP2 / (TP2 + FP2) if (TP2 + FP2) else 0\n",
    "                R2 = TP2 / (TP2 + FN2) if (TP2 + FN2) else 0\n",
    "                F2 = 2 * P2 * R2 / (P2 + R2) if (P2 + R2) else 0\n",
    "                \n",
    "                tqdm_epoch.set_postfix(loss='{}'.format(loss_sum), P=P, R=R, F1=F1, P2=P2, R2=R2, F2=F2, refresh=False)\n",
    "                model.train()\n",
    "                \n",
    "                result_file.write('{}, {}, {}, {}, {}, {}, {}, {}, {}\\n'.format(e, loss_sum, P, R, F1, TP, FP, TN, FN))\n",
    "                result_file.flush()\n",
    "                \n",
    "            result_file.close()\n",
    "            del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f381d70e597214683a7966ab2fd2893e10012246e6f9f6e78076ec4753f3d72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
